{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHx+EhaF1h/BVAsOz3RzHN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biwanun1690/Resume-Builder-and-Job-Selection-Algorithm-1511/blob/Algorithm-resume-vacancy/transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "!pip install translate\n",
        "!pip install googletrans\n",
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora\n",
        "!pip install gensim\n",
        "!pip install nltk pymorphy2\n",
        "!pip install pymystem3\n",
        "import googletrans\n",
        "import asyncio\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from googletrans import Translator\n",
        "from pymystem3 import Mystem\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "EBdHN6fA3KNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be4f53e-4843-4a79-a8a7-23b294f2784f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from translate) (8.1.8)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from translate) (5.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from translate) (2.32.3)\n",
            "Collecting libretranslatepy==2.1.1 (from translate)\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl.metadata (233 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (2025.1.31)\n",
            "Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-4.0.2\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d2c0ed34ab6b8b209e8d9f43287c4d971a5d113edd87ff878dd17e54d850a0e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Requirement already satisfied: pymystem3 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pymystem3) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Soh3RdYDwctE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05153e8b-60b8-48e7-c665-253cbd389dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fullname                                     Чижов Андрей Тимофеевич\n",
            "date_of_birth                                             2003-02-21\n",
            "gender                                                       мужской\n",
            "email                                        num-ugideju67@yandex.ru\n",
            "phone                                                (8549)595-64-54\n",
            "address                                 г. Москва ул.Тартар д.24 к.1\n",
            "education                                                     Высшее\n",
            "institution          Высшая академическая школа графического дизайна\n",
            "faculty                                                   3D графика\n",
            "year_graduation                                                 2021\n",
            "status                                     Средний работник с опытом\n",
            "area_work                                                     Дизайн\n",
            "branch                                                   3D дизайнер\n",
            "experience                                             от 1 до 3 лет\n",
            "achievements       Написал статью, опубликованную в профессиональ...\n",
            "company                                                     ProtoPuf\n",
            "skills             Создание визульных спецэффектов, использование...\n",
            "dtype: object\n",
            "\n",
            "name                                                  Дизайнер-художник\n",
            "area_work                                                        Дизайн\n",
            "salary_from                                                      100000\n",
            "salary_to                                                        150000\n",
            "addres                                      г. Москва ул.Тушканчик д.10\n",
            "employer                                                   Надежда Луна\n",
            "requirement           Понимания специфики различных материалов и сов...\n",
            "responsibility        Отвечать за разработку визуальных концепций ди...\n",
            "contacts                                                    76873642384\n",
            "schedule                                                    Полный день\n",
            "working_days                                                        NaN\n",
            "\\twork_format                                            Сменный график\n",
            "working_hours                                                   5 часов\n",
            "night_shifts                                                      False\n",
            "professional_roles                                 Графический дизайнер\n",
            "experience                                                от 1 до 3 лет\n",
            "employment                                             Проектная работа\n",
            "internship                                                        False\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "data = ['Чижов Андрей Тимофеевич', '2003-02-21', 'мужской', 'num-ugideju67@yandex.ru', '(8549)595-64-54', 'г. Москва ул.Тартар д.24 к.1',\n",
        "         'Высшее', 'Высшая академическая школа графического дизайна', '3D графика', '2021',\n",
        "         'Средний работник с опытом', 'Дизайн', '3D дизайнер',\n",
        "         'от 1 до 3 лет', 'Написал статью, опубликованную в профессиональном журнале', 'ProtoPuf', 'Создание визульных спецэффектов, использование современных технологий работы создания моделей.']\n",
        "index = ['fullname', 'date_of_birth', 'gender', 'email', 'phone', 'address',\n",
        "         'education', 'institution', 'faculty', 'year_graduation',\n",
        "         'status', 'area_work', 'branch',\n",
        "         'experience', 'achievements', 'company',\n",
        "         'skills']\n",
        "resume = pd.Series(data, index=index)\n",
        "\n",
        "data = ['Дизайнер-художник', 'Дизайн', '100000', '150000', 'г. Москва ул.Тушканчик д.10', 'Надежда Луна',\n",
        "         'Понимания специфики различных материалов и современных технологий нанесения (офсетная и цифровая печать, предпечатная подготовка).',\n",
        "         'Отвечать за разработку визуальных концепций дизайна и их реализацию для различных носителей (полиграфия, текстиль, фарфор и тд).',\n",
        "         '76873642384', 'Полный день', np.NaN, 'Сменный график', '5 часов', False, 'Графический дизайнер', 'от 1 до 3 лет',\n",
        "        'Проектная работа', False]\n",
        "\n",
        "index = ['name',\t'area_work',\t'salary_from', \t'salary_to',\t'addres',\t'employer',\t'requirement',\t'responsibility',\n",
        "         'contacts',\t'schedule',\t'working_days','\twork_format',\t'working_hours',\t'night_shifts',\n",
        "         'professional_roles',\t'experience', 'employment', 'internship']\n",
        "vacancy = pd.Series(data, index=index)\n",
        "\n",
        "print(resume)\n",
        "print()\n",
        "print(vacancy)\n",
        "\n",
        "resume_text = resume['achievements'] + '. ' + resume['skills']\n",
        "vacancy_text = vacancy['requirement'] + ' ' +  vacancy['responsibility']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import Translator\n",
        "\n",
        "translator = Translator(from_lang=\"ru\", to_lang=\"en\")\n",
        "skills = translator.translate(skills)\n",
        "need_skills = translator.translate(need_skills)\n",
        "print(skills)\n",
        "print(need_skills)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCgoCv2pe5A3",
        "outputId": "445ed8b1-8f86-48e4-96db-06a93c08c56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creation of visual special effects, the use of modern technologies for creating models.\n",
            "Understanding the specifics of various materials and modern application technologies (offset and digital printing, prepress). Responsible for the development of visual design concepts and their implementation for various media (printing, textiles, porcelain, etc.).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def processing(text):\n",
        "  # Регулярные выражения\n",
        "  pattern = r\"[^\\w]\"\n",
        "  text = re.sub(pattern, \" \", text)\n",
        "\n",
        "  # Лемматезация\n",
        "  m = Mystem()\n",
        "  lemmas = m.lemmatize(text)\n",
        "  text = \"\".join(lemmas).strip()\n",
        "\n",
        "  # Токенизация\n",
        "  text = nltk.sent_tokenize(text)\n",
        "  text = [nltk.word_tokenize(sentence) for sentence in text]\n",
        "\n",
        "  # Стоп-слова\n",
        "  stop_words = set(stopwords.words(\"russian\"))\n",
        "  for i in range(len(text)):\n",
        "    text[i] = [word for word in text[i] if not word in stop_words]\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "lo_8ogn5CKeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resume_text)\n",
        "print(vacancy_text)\n",
        "resume_text = processing(resume_text)\n",
        "vacancy_text = processing(vacancy_text)\n",
        "print(resume_text)\n",
        "print(vacancy_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PNdpHIdFkXO",
        "outputId": "e969f141-35fb-420a-8613-c4bfcb57a085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Написал статью, опубликованную в профессиональном журнале. Создание визульных спецэффектов, использование современных технологий работы создания моделей.\n",
            "Понимания специфики различных материалов и современных технологий нанесения (офсетная и цифровая печать, предпечатная подготовка). Отвечать за разработку визуальных концепций дизайна и их реализацию для различных носителей (полиграфия, текстиль, фарфор и тд).\n",
            "[['написать', 'статья', 'опубликовывать', 'профессиональный', 'журнал', 'создание', 'визульный', 'спецэффект', 'использование', 'современный', 'технология', 'работа', 'создание', 'модель']]\n",
            "[['понимание', 'специфика', 'различный', 'материал', 'современный', 'технология', 'нанесение', 'офсетный', 'цифровой', 'печать', 'предпечатный', 'подготовка', 'отвечать', 'разработка', 'визуальный', 'концепция', 'дизайн', 'реализация', 'различный', 'носитель', 'полиграфия', 'текстиль', 'фарфор', 'тд']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentences = resume_text + vacancy_text\n",
        "print(sentences)\n",
        "\n",
        "# Создание модели Word2Vec\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "model.train(sentences, total_examples=model.corpus_count, epochs=10)\n",
        "\n",
        "count_similar_words = 0\n",
        "resume_text_ = resume_text[0]\n",
        "vacancy_text_ = vacancy_text[0]\n",
        "for word in resume_text_:\n",
        "  # Получение вектора слова\n",
        "  vector = model.wv[word]\n",
        "  # Поиск похожих слов\n",
        "  similar_words = model.wv.most_similar(word)\n",
        "  for similar_word in similar_words:\n",
        "    if similar_word[0] in vacancy_text_ and similar_word[1] >= 0.15:\n",
        "      count_similar_words += 1\n",
        "\n",
        "print(similar_words)\n",
        "print(count_similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bGGlXZWF_kY",
        "outputId": "08bc74a7-172e-4abb-c267-0de3722f5075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['написать', 'статья', 'опубликовывать', 'профессиональный', 'журнал', 'создание', 'визульный', 'спецэффект', 'использование', 'современный', 'технология', 'работа', 'создание', 'модель'], ['понимание', 'специфика', 'различный', 'материал', 'современный', 'технология', 'нанесение', 'офсетный', 'цифровой', 'печать', 'предпечатный', 'подготовка', 'отвечать', 'разработка', 'визуальный', 'концепция', 'дизайн', 'реализация', 'различный', 'носитель', 'полиграфия', 'текстиль', 'фарфор', 'тд']]\n",
            "[('офсетный', 0.3198152482509613), ('спецэффект', 0.1751776486635208), ('полиграфия', 0.12919537723064423), ('материал', 0.12135910987854004), ('визульный', 0.11133334785699844), ('фарфор', 0.10961601138114929), ('опубликовывать', 0.10607045143842697), ('визуальный', 0.09713415056467056), ('различный', 0.09587042778730392), ('статья', 0.08073121309280396)]\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_similar_word(resume, vacancy):\n",
        "  sentences = resume + vacancy\n",
        "  model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "  model.train(sentences, total_examples=model.corpus_count, epochs=10)\n",
        "  count = 0\n",
        "  resume_text = resume[0]\n",
        "  vacancy_text = vacancy[0]\n",
        "  for word in resume_text_:\n",
        "    # Получение вектора слова\n",
        "    vector = model.wv[word]\n",
        "    # Поиск похожих слов\n",
        "    similar_words = model.wv.most_similar(word)\n",
        "    for similar_word in similar_words:\n",
        "      if similar_word[0] in vacancy_text and similar_word[1] >= 0.15:\n",
        "        count += 1\n",
        "\n",
        "  return count"
      ],
      "metadata": {
        "id": "iRg1_gSo0jEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_similar_word(resume_text, vacancy_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK6fE5nd2BnD",
        "outputId": "3434bd16-43a3-4cca-9ab9-7cf3585fb990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример словаря\n",
        "my_dict = {\n",
        "    'a': 5,\n",
        "    'b': 2,\n",
        "    'c': 9,\n",
        "    'd': 1,\n",
        "    'e': 7,\n",
        "    'f': 3,\n",
        "    'g': 8,\n",
        "    'h': 6,\n",
        "    'i': 4,\n",
        "    'j': 10,\n",
        "    'k': 0\n",
        "}\n",
        "\n",
        "# Сортировка словаря по значениям и получение первых 10 объектов\n",
        "my_dict = sorted(my_dict.items(), key=lambda item: item[1], reverse=True)[:10]\n",
        "\n",
        "\n",
        "# Преобразование обратно в словарь (если нужно)\n",
        "top_10_dict = dict(my_dict)\n",
        "\n",
        "print(top_10_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4Kp25Iq9y6A",
        "outputId": "8a94ad93-1b25-4f6f-dfdf-da9ef833b424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'j': 10, 'c': 9, 'g': 8, 'e': 7, 'h': 6, 'a': 5, 'i': 4, 'f': 3, 'b': 2, 'd': 1}\n"
          ]
        }
      ]
    }
  ]
}